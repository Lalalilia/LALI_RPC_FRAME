### 网络模型

程序使用Reactor事件驱动模型，使用多线程提高并发度。为避免线程频繁创建和销毁带来的开销，使用线程池，在程序的开始创建固定数量的线程。使用epoll作为IO多路复用的实现方式。



### 事件驱动模型

Reactor EventLoop 核心工作步骤：

**1.建立过程：**

首先建立一个EventLoop类，建立一个Channel类绑定到一个事件循环后调用更新函数，函数在EventLoop类中调用updateChannel()来更新poller中的事件表，到此一个事件就加入了EventLoop工作的流程中；

**2.执行过程：**

在Eventloop类中loop()函数中调用Poller类中的poll()来获取活跃事件，并总的记录在一个活跃事件表activeChannels中，之后遍历这个活跃事件表，逐个调用活跃事件Channel中的handleEvent()来回调事件函数。

在此中，EventLoop就是领导，Poller是书记员，Channel是打工仔，领导日常询问书记员（调用poll()），书记员找到有工作请求的打工仔（poll()中寻找活动的fd然后更新到活跃事件activeChannel中），执行官指导后就嘱咐打工仔干他对应的活（activeChannel->handleEvent()）

**3.runInLoop/queueInLoop：**	

走后门的runInLoop，在EventLoop中，领导人EventLoop专门设置了一个doPendingFunctor()环节，来额外接受不在poller记录本里面的事件，但还存在一个pendingFunctors_，专门记录额外事件名单，领导人EventLoop平常都会阻塞在poll()函数中但没事做，如果这是有额外事件提交（queueInLoop）了，就会weakup()（使用eventfd唤醒EventLoop线程）直接通知到poll()函数中，让EventLoop可以跳出poll()的阻塞，然后来doPendingFunctor()。

<img src="https://gitee.com/lalalilia/NetWordCode/raw/master/images/EventLoop工作步骤.jpg" style="zoom:50%;" />



#### 定时器Timer

Timer设计由三部分组成，

Timer.h/Timer.cpp 负责实现单个定时器Timer的信息储存，存储定时业务的需求；

TimerId.h 负责封装Timer类提供给用户；

TimerQueue.h/TimerQueue.cpp实现了TimerQueue类，使用timerfd创建定时器，注册 timerChannel，并注册到poller类维护的channel事件表中。

EventLoop中含有TimerQueue，并通过runInLoop的方式来创建定时器。



#### 缓冲Buffer类

<img src="https://gitee.com/lalalilia/NetWordCode/raw/master/images/缓冲buffer类.jpg" style="zoom:50%;" />

**简介：**将一块内存空间分为3个部分，prepend，readable，writable；可写可读以及预留空间，实现了使用同一个buffer实现读写；预留空间的作用有，能够以极低的代价在数据前加上几个字符，利用空间换时间，例如需要表示一个消息的长度，序列化一个消息，我们可以一直append数据到buffer，完成之后，再在数据前面加上消息长度；

**读fd：**在buffer读数据时使用readv散布读技术scatter io，可以把数据读到不连续空间中，通常可以一次读完数据，避免重复调用read，请栈上空间作为备用空间，避免了内存浪费，同时muduo事件模式是level trigger，因此这个函数不会反复调用read直至返回EAEGIN，若buffer装不下，放入栈上空间后再append入buffer中。

非阻塞IO的核心思想就是避免阻塞在read()或write()或其他IO系统调用上，让一个线程尽可能的多服务于多个socket连接；

例如，一个程序想通过TCP发送100KB的数据，但是在write()调用中，程序只接受了80K，这时肯定不想要一直在write调用中等待数据写完，程序应该要尽快交出控制权；网络库应该接管这20K，把他们保存在TcpConnection的OutputBuffer上，然后注册POLLOUT事件，一旦socket变得可写就立即发送数据，如果此时程序又写入了50KB，而此时buffer里面还有20K没有发送，则此时网络库不直接调用write，而是将数据追加到buffer后面，等待socket可写而一起写入；如果buffer不为空，程序想要关闭连接，而TCPconnection::shutdown()没有直接关闭TCP连接，而是数据发送完毕后才关闭；

网络库处理可读事件的时候，可能会一次性不能完全接受数据，我们需要尽力一次性把socket里的数据读完，否则会反复触发POLLIN事件；对于这种数据不完整的情况，我们可以将受到的数据先放在inputbuffer里面，等构成了一条完整的信息后再通知程序的业务逻辑；



#### 并发模型

<img src="https://gitee.com/lalalilia/NetWordCode/raw/master/images/并发模型.jpg" style="zoom:50%;" />

Reactor模式，IO复用，非阻塞IO，线程池

TcpServer只有一个，用于接受新连接，在接受到新连接之后，在线程池通过 **Round-Robin** 的方式从中获取EventLoop线程，并把TcpConnection 分配给 EventLoop 线程，此时不用担心 EventLoop 正阻塞在poll() 函数中，因为使用 runInLoop 函数通过 **eventfd** 直接唤醒线程，进行来连接处理。

TcpConnection 可有多个，连接响应和传送消息可通过设置TcpServer回调函数实现，TcpConnection 有读写Channel，在必要时注册进Poller事件表。



#### Reactor 和 Proactor 区别

reactor 模型是同步非阻塞IO模型，proactor 是异步非阻塞IO模型；我们可以对比二者执行步骤（以读事件为例）

**Reactor ：**

应用程序注册读就绪事件和相关联的事件处理器；

事件分发器等待事件的发生

当发生就绪事件的时候，事件分发器调用第一步注册的事件处理器；

事件处理器首先执行实际的读取操作，然后根据读取到的内容进行进一步的处理；

**Proactor：**

应用程序初始化一个异步读取操作，然后注册相应的事件分发器，此时事件处理器不关注读取就绪事件，而是关注读取完成事件，这是区别于Reactor的关键；

事件分发器等待读取操作完成事件；

在事件分发器等待读取操作完成的时候，操作系统调用内核线程完成读取操作，并将读取的内容放入用户传递来的缓存区中，这也是和reactor不同的一点；

事件分发器捕获到读取完成事件后，激活应用程序注册的事件处理器，事件处理器直接从缓存区读取数据，而不需要进行实际的读取操作；

从以上可以得出，两种模式的主要区别就是真正的读取和写入操作是由谁来完成的，reactor 中需要应用程序自己读取或写入数据，而在 proactor 中应用程序不需要进行实际的读写过程，操作系统会读取缓存区或者写入缓存区到正在的IO设备；











